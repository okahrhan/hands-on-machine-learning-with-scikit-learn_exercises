{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a54712d-2e17-47a6-b05c-3891fb28d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import html\n",
    "import string\n",
    "import unicodedata\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "from typing import Tuple, List, Dict, Any, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4193f841-f7f6-4b09-b532-56fcfb0694e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAFE_PUNCTS = set(\"!?.:,;\")\n",
    "WORD_RE = re.compile(r\"[A-Za-z']+\")\n",
    "URL_RE = re.compile(r\"(https?://\\S+|www\\.\\S+)\", re.IGNORECASE)\n",
    "EMAIL_RE = re.compile(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\")\n",
    "MONEY_RE = re.compile(r\"(\\$|€|£)\\s?\\d[\\d,\\.]*\")\n",
    "NUM_RE = re.compile(r\"\\b\\d+(?:[\\.,]\\d+)?\\b\")\n",
    "HTML_TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "WHITESPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "REPLY_PREFIX_RE = re.compile(r\"^\\s*(re|fw|fwd)\\s*[:\\-]\\s*\", re.IGNORECASE)\n",
    "\n",
    "STOPWORDS = {\n",
    "    \"the\",\"and\",\"is\",\"in\",\"to\",\"of\",\"a\",\"for\",\"on\",\"with\",\"that\",\"this\",\"it\",\"as\",\"at\",\"an\",\"be\",\"by\",\"from\",\"or\",\n",
    "    \"are\",\"was\",\"were\",\"will\",\"would\",\"can\",\"could\",\"should\",\"has\",\"have\",\"had\",\"not\",\"no\",\"but\",\"if\",\"then\",\"so\",\n",
    "    \"do\",\"does\",\"did\",\"we\",\"you\",\"he\",\"she\",\"they\",\"them\",\"his\",\"her\",\"their\",\"our\",\"us\",\"i\",\"me\",\"my\",\"your\",\"yours\"\n",
    "}\n",
    "\n",
    "SPAM_WORDS = {\n",
    "    \"free\",\"click\",\"offer\",\"winner\",\"viagra\",\"earn\",\"credit\",\"urgent\",\"limited\",\"deal\",\"bonus\",\"buy\",\"cheap\",\n",
    "    \"win\",\"guarantee\",\"money\",\"investment\",\"casino\",\"loan\",\"mortgage\",\"million\",\"billion\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef2063be-8082-4a02-a6a7-44dbe35e315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_lower(s):\n",
    "    return s.lower() if isinstance(s, str) else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34363e02-bad9-4626-8fd5-9123fadf36cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç yi c\n",
    "def strip_accents(s):\n",
    "    if not isinstance(s, str):\n",
    "        return ''\n",
    "    return ''.join(\n",
    "        ch for ch in unicodedata.normalize('NFKD', s)\n",
    "        if not unicodedata.combining(ch)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "777eb020-c2c2-45ee-ac5d-664f491ab56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete spaces\n",
    "def normalize_spaces(s):\n",
    "    return WHITESPACE_RE.sub(\" \", s).strip()\n",
    "\n",
    "def html_to_text(s):\n",
    "    unescaped = html.unescape(s)\n",
    "    no_tags = HTML_TAG_RE.sub(\" \", unescaped)\n",
    "    return normalize_spaces(no_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46dd7c64-ff1c-45f2-815e-a274476b0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_patterns(s: str) -> Tuple[str, Dict[str, int]]:\n",
    "    counts = {\n",
    "        \"url_count\": 0,\n",
    "        \"email_count\": 0,\n",
    "        \"money_count\": 0,\n",
    "        \"num_count\": 0\n",
    "    }\n",
    "    def _count_and_replace(pattern: re.Pattern, repl: str, text: str, key: str) -> str:\n",
    "        matches = pattern.findall(text)\n",
    "        counts[key] += len(matches)\n",
    "        return pattern.sub(repl, text)\n",
    "\n",
    "    out = s\n",
    "    out = _count_and_replace(URL_RE, \" URLTOK \", out, \"url_count\")\n",
    "    out = _count_and_replace(EMAIL_RE, \" EMAILTOK \", out, \"email_count\")\n",
    "    out = _count_and_replace(MONEY_RE, \" MONEYTOK \", out, \"money_count\")\n",
    "    out = _count_and_replace(NUM_RE, \" NUMTOK \", out, \"num_count\")\n",
    "    return normalize_spaces(out), counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb7bded7-06cb-47d7-a26a-eb6976155cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct_keep_basic(s):\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    keep = \"\".join(SAFE_PUNCTS)\n",
    "    table = str.maketrans(\"\", \"\", \"\".join(ch for ch in string.punctuation if ch not in keep))\n",
    "    return s.translate(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d2aa37e-da33-4723-b478-74fc6b6e8921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_upper_ratio(s):\n",
    "    if not s:\n",
    "        return 0.0\n",
    "    upp = sum(1 for ch in s if ch.isalpha() and ch.isupper())\n",
    "    letters = sum(1 for ch in s if ch.isalpha())\n",
    "    return upp / letters if letters else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "defbcb60-3f6e-4990-bdbc-74935265a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_ascii_ratio(s):\n",
    "    if not s:\n",
    "        return 0.0\n",
    "    total = len(s)\n",
    "    non_ascii = sum(1 for ch in s if ord(ch) > 127)\n",
    "    return non_ascii / total if total else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcfd57be-dd79-485e-acb0-f6a2b28dab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_len(words: List[str]) -> float:\n",
    "    if not words:\n",
    "        return 0.0\n",
    "    return float(np.mean([len(w) for w in words if len(w) > 0])) if any(len(w)>0 for w in words) else 0.0\n",
    "\n",
    "def lexical_diversity(words: List[str]) -> float:\n",
    "    if not words:\n",
    "        return 0.0\n",
    "    uniq = len(set(words))\n",
    "    return uniq / len(words) if len(words) else 0.0\n",
    "\n",
    "def stopword_ratio(words: List[str]) -> float:\n",
    "    if not words:\n",
    "        return 0.0\n",
    "    sw = sum(1 for w in words if w in STOPWORDS)\n",
    "    return sw / len(words)\n",
    "\n",
    "def spam_word_count(words: List[str]) -> int:\n",
    "    return sum(1 for w in words if w in SPAM_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8010dcc-896e-496c-af55-5075a92918e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email_file(fp: str) -> Tuple[str, str, Dict[str, Any]]:\n",
    "    with open(fp, \"rb\") as f:\n",
    "        msg = BytesParser(policy=policy.default).parse(f)\n",
    "\n",
    "    subject = msg[\"subject\"] or \"\"\n",
    "    meta = {\n",
    "        \"is_multipart\": bool(msg.is_multipart()),\n",
    "        \"num_parts\": 1,\n",
    "        \"has_html_part\": False\n",
    "    }\n",
    "\n",
    "    body = \"\"\n",
    "    if msg.is_multipart():\n",
    "        parts = list(msg.walk())\n",
    "        meta[\"num_parts\"] = len([p for p in parts if p.get_content_maintype() != \"multipart\"])\n",
    "        for part in parts:\n",
    "            ctype = part.get_content_type()\n",
    "            if ctype == \"text/plain\":\n",
    "                try:\n",
    "                    body += part.get_content()\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        body += part.get_payload(decode=True).decode(errors=\"ignore\")\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            elif ctype == \"text/html\":\n",
    "                meta[\"has_html_part\"] = True\n",
    "                try:\n",
    "                    body_html = part.get_content()\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        body_html = part.get_payload(decode=True).decode(errors=\"ignore\")\n",
    "                    except Exception:\n",
    "                        body_html = \"\"\n",
    "                body += \" \" + html_to_text(body_html)\n",
    "    else:\n",
    "        ctype = msg.get_content_type()\n",
    "        if ctype == \"text/plain\":\n",
    "            try:\n",
    "                body = msg.get_content()\n",
    "            except Exception:\n",
    "                body = msg.get_payload(decode=True).decode(errors=\"ignore\")\n",
    "        elif ctype == \"text/html\":\n",
    "            meta[\"has_html_part\"] = True\n",
    "            try:\n",
    "                body_html = msg.get_content()\n",
    "            except Exception:\n",
    "                body_html = msg.get_payload(decode=True).decode(errors=\"ignore\")\n",
    "            body = html_to_text(body_html)\n",
    "        else:\n",
    "            # Fallback\n",
    "            try:\n",
    "                body = msg.get_content()\n",
    "            except Exception:\n",
    "                try:\n",
    "                    body = msg.get_payload(decode=True).decode(errors=\"ignore\")\n",
    "                except Exception:\n",
    "                    body = \"\"\n",
    "\n",
    "    return subject or \"\", body or \"\", meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52282e8c-7d76-499f-bba4-1a3034347978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clean_text(subject: str, body: str) -> Tuple[str, Dict[str, Any]]:\n",
    "    subj = subject if isinstance(subject, str) else \"\"\n",
    "    subj_unescaped = html.unescape(subj)\n",
    "    subj_no_tags = HTML_TAG_RE.sub(\" \", subj_unescaped)\n",
    "    subj_norm = normalize_spaces(subj_no_tags)\n",
    "\n",
    "    body_raw = body if isinstance(body, str) else \"\"\n",
    "    \n",
    "    body_unescaped = html.unescape(body_raw)\n",
    "    body_no_tags = HTML_TAG_RE.sub(\" \", body_unescaped)\n",
    "    body_norm = normalize_spaces(body_no_tags)\n",
    "    merged = normalize_spaces(f\"{subj_norm} . {body_norm}\")\n",
    "    replaced, counts = replace_patterns(merged)\n",
    "    no_punct = remove_punct_keep_basic(replaced)\n",
    "    lowered = safe_lower(no_punct)\n",
    "    deaccent = strip_accents(lowered)\n",
    "    cleaned = normalize_spaces(deaccent)\n",
    "    return cleaned, counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d675b15-daa1-46c1-ac49-0324142b260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(text: str) -> List[str]:\n",
    "    if not text:\n",
    "        return []\n",
    "    return [m.group(0).lower() for m in WORD_RE.finditer(text)]\n",
    "\n",
    "def subject_features(subject: str) -> Dict[str, Any]:\n",
    "    s = subject or \"\"\n",
    "    feats = {\n",
    "        \"subject_len\": len(s),\n",
    "        \"subject_upper_ratio\": calc_upper_ratio(s),\n",
    "        \"subject_exclaim\": s.count(\"!\"),\n",
    "        \"subject_has_reply_prefix\": 1 if REPLY_PREFIX_RE.search(s or \"\") else 0,\n",
    "    }\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5778e09-30ad-47e7-8fbf-70a7daf65a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structural_features(text: str, meta: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    s = text or \"\"\n",
    "    lines = s.splitlines()\n",
    "    num_lines = len(lines)\n",
    "    mean_line_len = float(np.mean([len(li) for li in lines])) if num_lines else 0.0\n",
    "    exclam_count = s.count(\"!\")\n",
    "    punct_count = sum(1 for ch in s if ch in string.punctuation)\n",
    "    feats = {\n",
    "        \"is_multipart\": int(bool(meta.get(\"is_multipart\", False))),\n",
    "        \"num_parts\": int(meta.get(\"num_parts\", 1)),\n",
    "        \"has_html_part\": int(bool(meta.get(\"has_html_part\", False))),\n",
    "        \"num_lines\": num_lines,\n",
    "        \"mean_line_len\": mean_line_len,\n",
    "        \"exclam_count\": exclam_count,\n",
    "        \"punct_count\": punct_count,\n",
    "        \"upper_ratio\": calc_upper_ratio(s),\n",
    "        \"non_ascii_ratio\": non_ascii_ratio(s),\n",
    "        \"char_count\": len(s),\n",
    "    }\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99df5fd7-a762-4c8b-85d9-a6461961974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_based_features(clean_text: str) -> Dict[str, Any]:\n",
    "    words = tokenize_words(clean_text)\n",
    "    feats = {\n",
    "        \"word_count\": len(words),\n",
    "        \"avg_word_len\": avg_word_len(words),\n",
    "        \"lexical_diversity\": lexical_diversity(words),\n",
    "        \"stopword_ratio\": stopword_ratio(words),\n",
    "        \"spam_word_count\": spam_word_count(words),\n",
    "    }\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "706698f6-57da-4c31-8079-1d673ffa02f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_domain_features(from_header: Optional[str]) -> Dict[str, Any]:\n",
    "    dom = \"\"\n",
    "    tld = \"\"\n",
    "    if from_header:\n",
    "        m = EMAIL_RE.search(from_header)\n",
    "        if m:\n",
    "            addr = m.group(0)\n",
    "            try:\n",
    "                dom = addr.split(\"@\", 1)[1].lower()\n",
    "            except Exception:\n",
    "                dom = \"\"\n",
    "    if dom:\n",
    "        parts = dom.split(\".\")\n",
    "        if len(parts) >= 2:\n",
    "            tld = parts[-1]\n",
    "    return {\n",
    "        \"from_domain\": dom,\n",
    "        \"from_tld\": tld\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fd56c08-7f98-4eb7-9150-68c2329694d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_dataset_files(data_dir: str) -> List[Tuple[str, str]]:\n",
    "    label_map = {\n",
    "        \"easy_ham\": \"ham\",\n",
    "        \"easy_ham_2\": \"ham\",\n",
    "        \"hard_ham\": \"ham\",\n",
    "        \"spam\": \"spam\",\n",
    "        \"spam_2\": \"spam\",\n",
    "    }\n",
    "    pairs: List[Tuple[str, str]] = []\n",
    "    for sub in sorted(os.listdir(data_dir)):\n",
    "        sub_path = os.path.join(data_dir, sub)\n",
    "        if not os.path.isdir(sub_path):\n",
    "            continue\n",
    "        if sub not in label_map:\n",
    "            continue\n",
    "        lab = label_map[sub]\n",
    "        for root, _, files in os.walk(sub_path):\n",
    "            for fn in files:\n",
    "                fp = os.path.join(root, fn)\n",
    "                if os.path.isfile(fp) and not fn.startswith(\".\"):\n",
    "                    pairs.append((lab, fp))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "215458ad-10cc-4c18-b836-fed337b7ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(label: str, file_path: str) -> Dict[str, Any]:\n",
    "    subj, body, meta = parse_email_file(file_path)\n",
    "    clean_text, counts = build_clean_text(subj, body)\n",
    "\n",
    "    subject_feats = subject_features(subj)\n",
    "    structural_feats = structural_features(f\"{subj} . {body}\", meta)\n",
    "    word_feats = word_based_features(clean_text)\n",
    "    from_header = \"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            msg = BytesParser(policy=policy.default).parse(f)\n",
    "        from_header = msg[\"from\"] or \"\"\n",
    "    except Exception:\n",
    "        from_header = \"\"\n",
    "    header_feats = header_domain_features(from_header)\n",
    "\n",
    "    out = {\n",
    "        \"path\": file_path,\n",
    "        \"subject\": subj,\n",
    "        \"body\": body,\n",
    "        \"text_all\": f\"{subj} . {body}\",\n",
    "        \"clean_text\": clean_text,\n",
    "        \"label\": label,\n",
    "        \"label_encoded\": 1 if label == \"spam\" else 0,\n",
    "    }\n",
    "    out.update(counts)\n",
    "    out.update(subject_feats)\n",
    "    out.update(structural_feats)\n",
    "    out.update(word_feats)\n",
    "    out.update(header_feats)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a94b226b-5b2f-4937-8fd1-cf38beb50053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_processing(\n",
    "    data_dir: str = \"data\",\n",
    "    output_file: str = \"emails_prepared.csv\",\n",
    ") -> pd.DataFrame:\n",
    "    pairs = iter_dataset_files(data_dir)\n",
    "    records: List[Dict[str, Any]] = []\n",
    "\n",
    "    for lab, fp in pairs:\n",
    "        try:\n",
    "            rec = process_row(lab, fp)\n",
    "            records.append(rec)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Parse/Process error: {fp} -> {e}\")\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "\n",
    "    for col in [\"subject\", \"body\", \"text_all\", \"clean_text\", \"from_domain\", \"from_tld\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(\"\").astype(str)\n",
    "\n",
    "    numeric_cols = [c for c in df.columns if c not in [\"path\",\"subject\",\"body\",\"text_all\",\"clean_text\",\"label\",\"from_domain\",\"from_tld\"]]\n",
    "    for c in numeric_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    save_path = os.path.join(os.getcwd(), output_file)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"[OK] saved: {save_path} (shape={df.shape})\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "131081a9-834c-4f1b-a8cc-5e9962306a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_incoming_email(subject: str, body: str) -> pd.DataFrame:\n",
    "    meta = {\"is_multipart\": False, \"num_parts\": 1, \"has_html_part\": (\"<html\" in (body or \"\").lower())}\n",
    "    clean_text, counts = build_clean_text(subject, body)\n",
    "    subject_feats = subject_features(subject)\n",
    "    structural_feats = structural_features(f\"{subject} . {body}\", meta)\n",
    "    word_feats = word_based_features(clean_text)\n",
    "    header_feats = {\"from_domain\": \"\", \"from_tld\": \"\"}\n",
    "\n",
    "    out = {\n",
    "        \"path\": \"\",\n",
    "        \"subject\": subject or \"\",\n",
    "        \"body\": body or \"\",\n",
    "        \"text_all\": f\"{subject or ''} . {body or ''}\",\n",
    "        \"clean_text\": clean_text,\n",
    "        \"label\": \"\",\n",
    "        \"label_encoded\": 0,\n",
    "    }\n",
    "    out.update(counts)\n",
    "    out.update(subject_feats)\n",
    "    out.update(structural_feats)\n",
    "    out.update(word_feats)\n",
    "    out.update(header_feats)\n",
    "\n",
    "    return pd.DataFrame([out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9de8aaf9-0317-4455-bc35-b32df11ea9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_incoming_rfc822(raw_bytes: bytes) -> pd.DataFrame:\n",
    "    with open(\"_tmp_incoming.eml\", \"wb\") as f:\n",
    "        f.write(raw_bytes)\n",
    "    try:\n",
    "        subj, body, meta = parse_email_file(\"_tmp_incoming.eml\")\n",
    "        df = process_incoming_email(subj, body)\n",
    "        df[\"is_multipart\"] = int(bool(meta.get(\"is_multipart\", False)))\n",
    "        df[\"num_parts\"] = int(meta.get(\"num_parts\", 1))\n",
    "        df[\"has_html_part\"] = int(bool(meta.get(\"has_html_part\", False)))\n",
    "        return df\n",
    "    finally:\n",
    "        try:\n",
    "            os.remove(\"_tmp_incoming.eml\")\n",
    "        except Exception:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b910e-4eba-4a50-8081-a35c84fd050d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25a66711-4b7f-4c6f-ac5e-5272a720afa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Kaydedildi: /home/kahir/Desktop/E-MAIL-REAL/emails_prepared.csv (shape=(9353, 32))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>text_all</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>url_count</th>\n",
       "      <th>email_count</th>\n",
       "      <th>money_count</th>\n",
       "      <th>...</th>\n",
       "      <th>upper_ratio</th>\n",
       "      <th>non_ascii_ratio</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>stopword_ratio</th>\n",
       "      <th>spam_word_count</th>\n",
       "      <th>from_domain</th>\n",
       "      <th>from_tld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/easy_ham/00001.7c53336b37003a9286aba55d29...</td>\n",
       "      <td>Re: New Sequences Window</td>\n",
       "      <td>Date:        Wed, 21 Aug 2002 10:54:46 -05...</td>\n",
       "      <td>Re: New Sequences Window .     Date:        We...</td>\n",
       "      <td>re: new sequences window . date: wed, numtok a...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1631</td>\n",
       "      <td>242</td>\n",
       "      <td>4.805785</td>\n",
       "      <td>0.516529</td>\n",
       "      <td>0.214876</td>\n",
       "      <td>0</td>\n",
       "      <td>munnari.oz.au</td>\n",
       "      <td>au</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/easy_ham/00002.9c4069e25e1ef370c078db7ee8...</td>\n",
       "      <td>[zzzzteana] RE: Alexander</td>\n",
       "      <td>Martin A posted:\\nTassos Papadopoulos, the Gre...</td>\n",
       "      <td>[zzzzteana] RE: Alexander . Martin A posted:\\n...</td>\n",
       "      <td>zzzzteana re: alexander . martin a posted: tas...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>927</td>\n",
       "      <td>110</td>\n",
       "      <td>4.927273</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>1</td>\n",
       "      <td>cursor-system.com</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/easy_ham/00003.860e3c3cee1b42ead714c5c874...</td>\n",
       "      <td>[zzzzteana] Moscow bomber</td>\n",
       "      <td>Man Threatens Explosion In Moscow \\n\\nThursday...</td>\n",
       "      <td>[zzzzteana] Moscow bomber . Man Threatens Expl...</td>\n",
       "      <td>zzzzteana moscow bomber . man threatens explos...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1779</td>\n",
       "      <td>252</td>\n",
       "      <td>5.023810</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>1</td>\n",
       "      <td>2ubh.com</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/easy_ham/00004.864220c5b6930b209cc287c361...</td>\n",
       "      <td>[IRR] Klez: The Virus That  Won't Die</td>\n",
       "      <td>Klez: The Virus That Won't Die\\n \\nAlready the...</td>\n",
       "      <td>[IRR] Klez: The Virus That  Won't Die . Klez: ...</td>\n",
       "      <td>irr klez: the virus that wont die . klez: the ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1167</td>\n",
       "      <td>169</td>\n",
       "      <td>4.887574</td>\n",
       "      <td>0.644970</td>\n",
       "      <td>0.295858</td>\n",
       "      <td>0</td>\n",
       "      <td>roscom.com</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/easy_ham/00005.bf27cdeaf0b8c4647ecd61b1d0...</td>\n",
       "      <td>Re: [zzzzteana] Nothing like mama used to make</td>\n",
       "      <td>&gt;  in adding cream to spaghetti carbonara, whi...</td>\n",
       "      <td>Re: [zzzzteana] Nothing like mama used to make...</td>\n",
       "      <td>re: zzzzteana nothing like mama used to make ....</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1101</td>\n",
       "      <td>145</td>\n",
       "      <td>4.531034</td>\n",
       "      <td>0.703448</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>1</td>\n",
       "      <td>ee.ed.ac.uk</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9348</th>\n",
       "      <td>data/spam_2/01397.f75f0dd0dd923faefa3e9cc5ecb8...</td>\n",
       "      <td>Preferred Non-Smoker Rates for Smokers</td>\n",
       "      <td>\\t Preferred Non-Smoker\\n \\t\\n Just what the ...</td>\n",
       "      <td>Preferred Non-Smoker Rates for Smokers .  \\t P...</td>\n",
       "      <td>preferred nonsmoker rates for smokers . prefer...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2246</td>\n",
       "      <td>317</td>\n",
       "      <td>5.309148</td>\n",
       "      <td>0.321767</td>\n",
       "      <td>0.198738</td>\n",
       "      <td>1</td>\n",
       "      <td>insiq.us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9349</th>\n",
       "      <td>data/spam_2/01400.b444b69845db2fa0a4693ca04e6a...</td>\n",
       "      <td>[ILUG] WILSON  KAMELA</td>\n",
       "      <td>ATTN:SIR/MADAN      \\n\\n                      ...</td>\n",
       "      <td>[ILUG] WILSON  KAMELA . ATTN:SIR/MADAN      \\n...</td>\n",
       "      <td>ilug wilson kamela . attn:sirmadan strictly co...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2575</td>\n",
       "      <td>394</td>\n",
       "      <td>4.928934</td>\n",
       "      <td>0.510152</td>\n",
       "      <td>0.403553</td>\n",
       "      <td>11</td>\n",
       "      <td>netscape.net</td>\n",
       "      <td>net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9350</th>\n",
       "      <td>data/spam_2/01398.8ca7045aae4184d56e8509dc5ad6...</td>\n",
       "      <td>How to get 10,000 FREE hits per day to any web...</td>\n",
       "      <td>Dear Subscriber,\\n\\nIf I could show you a way ...</td>\n",
       "      <td>How to get 10,000 FREE hits per day to any web...</td>\n",
       "      <td>how to get numtok free hits per day to any web...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2526</td>\n",
       "      <td>349</td>\n",
       "      <td>4.550143</td>\n",
       "      <td>0.530086</td>\n",
       "      <td>0.409742</td>\n",
       "      <td>10</td>\n",
       "      <td>yahoo.lv</td>\n",
       "      <td>lv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9351</th>\n",
       "      <td>data/spam_2/01399.2319643317e2c5193d574e40a718...</td>\n",
       "      <td>Cannabis Difference</td>\n",
       "      <td>****Mid-Summer Customer Appreciation SALE!****...</td>\n",
       "      <td>Cannabis Difference . ****Mid-Summer Customer ...</td>\n",
       "      <td>cannabis difference . midsummer customer appre...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077989</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>23803</td>\n",
       "      <td>3417</td>\n",
       "      <td>5.578578</td>\n",
       "      <td>0.282411</td>\n",
       "      <td>0.240269</td>\n",
       "      <td>22</td>\n",
       "      <td>dialix.oz.au</td>\n",
       "      <td>au</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9352</th>\n",
       "      <td>data/spam_2/00007.acefeee792b5298f8fee175f9f65...</td>\n",
       "      <td>New Product Announcement</td>\n",
       "      <td>NEW PRODUCT ANNOUNCEMENT\\n\\nFrom: OUTSOURCE EN...</td>\n",
       "      <td>New Product Announcement . NEW PRODUCT ANNOUNC...</td>\n",
       "      <td>new product announcement . new product announc...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1850</td>\n",
       "      <td>265</td>\n",
       "      <td>5.584906</td>\n",
       "      <td>0.550943</td>\n",
       "      <td>0.316981</td>\n",
       "      <td>1</td>\n",
       "      <td>outsrc-em.com</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9353 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  \\\n",
       "0     data/easy_ham/00001.7c53336b37003a9286aba55d29...   \n",
       "1     data/easy_ham/00002.9c4069e25e1ef370c078db7ee8...   \n",
       "2     data/easy_ham/00003.860e3c3cee1b42ead714c5c874...   \n",
       "3     data/easy_ham/00004.864220c5b6930b209cc287c361...   \n",
       "4     data/easy_ham/00005.bf27cdeaf0b8c4647ecd61b1d0...   \n",
       "...                                                 ...   \n",
       "9348  data/spam_2/01397.f75f0dd0dd923faefa3e9cc5ecb8...   \n",
       "9349  data/spam_2/01400.b444b69845db2fa0a4693ca04e6a...   \n",
       "9350  data/spam_2/01398.8ca7045aae4184d56e8509dc5ad6...   \n",
       "9351  data/spam_2/01399.2319643317e2c5193d574e40a718...   \n",
       "9352  data/spam_2/00007.acefeee792b5298f8fee175f9f65...   \n",
       "\n",
       "                                                subject  \\\n",
       "0                              Re: New Sequences Window   \n",
       "1                             [zzzzteana] RE: Alexander   \n",
       "2                             [zzzzteana] Moscow bomber   \n",
       "3                 [IRR] Klez: The Virus That  Won't Die   \n",
       "4        Re: [zzzzteana] Nothing like mama used to make   \n",
       "...                                                 ...   \n",
       "9348             Preferred Non-Smoker Rates for Smokers   \n",
       "9349                              [ILUG] WILSON  KAMELA   \n",
       "9350  How to get 10,000 FREE hits per day to any web...   \n",
       "9351                                Cannabis Difference   \n",
       "9352                           New Product Announcement   \n",
       "\n",
       "                                                   body  \\\n",
       "0         Date:        Wed, 21 Aug 2002 10:54:46 -05...   \n",
       "1     Martin A posted:\\nTassos Papadopoulos, the Gre...   \n",
       "2     Man Threatens Explosion In Moscow \\n\\nThursday...   \n",
       "3     Klez: The Virus That Won't Die\\n \\nAlready the...   \n",
       "4     >  in adding cream to spaghetti carbonara, whi...   \n",
       "...                                                 ...   \n",
       "9348   \\t Preferred Non-Smoker\\n \\t\\n Just what the ...   \n",
       "9349  ATTN:SIR/MADAN      \\n\\n                      ...   \n",
       "9350  Dear Subscriber,\\n\\nIf I could show you a way ...   \n",
       "9351  ****Mid-Summer Customer Appreciation SALE!****...   \n",
       "9352  NEW PRODUCT ANNOUNCEMENT\\n\\nFrom: OUTSOURCE EN...   \n",
       "\n",
       "                                               text_all  \\\n",
       "0     Re: New Sequences Window .     Date:        We...   \n",
       "1     [zzzzteana] RE: Alexander . Martin A posted:\\n...   \n",
       "2     [zzzzteana] Moscow bomber . Man Threatens Expl...   \n",
       "3     [IRR] Klez: The Virus That  Won't Die . Klez: ...   \n",
       "4     Re: [zzzzteana] Nothing like mama used to make...   \n",
       "...                                                 ...   \n",
       "9348  Preferred Non-Smoker Rates for Smokers .  \\t P...   \n",
       "9349  [ILUG] WILSON  KAMELA . ATTN:SIR/MADAN      \\n...   \n",
       "9350  How to get 10,000 FREE hits per day to any web...   \n",
       "9351  Cannabis Difference . ****Mid-Summer Customer ...   \n",
       "9352  New Product Announcement . NEW PRODUCT ANNOUNC...   \n",
       "\n",
       "                                             clean_text label  label_encoded  \\\n",
       "0     re: new sequences window . date: wed, numtok a...   ham              0   \n",
       "1     zzzzteana re: alexander . martin a posted: tas...   ham              0   \n",
       "2     zzzzteana moscow bomber . man threatens explos...   ham              0   \n",
       "3     irr klez: the virus that wont die . klez: the ...   ham              0   \n",
       "4     re: zzzzteana nothing like mama used to make ....   ham              0   \n",
       "...                                                 ...   ...            ...   \n",
       "9348  preferred nonsmoker rates for smokers . prefer...  spam              1   \n",
       "9349  ilug wilson kamela . attn:sirmadan strictly co...  spam              1   \n",
       "9350  how to get numtok free hits per day to any web...  spam              1   \n",
       "9351  cannabis difference . midsummer customer appre...  spam              1   \n",
       "9352  new product announcement . new product announc...  spam              1   \n",
       "\n",
       "      url_count  email_count  money_count  ...  upper_ratio  non_ascii_ratio  \\\n",
       "0             1            1            0  ...     0.047527         0.000000   \n",
       "1             2            1            0  ...     0.077441         0.000000   \n",
       "2             2            1            0  ...     0.073933         0.000000   \n",
       "3             2            1            0  ...     0.059929         0.000000   \n",
       "4             3            1            0  ...     0.060893         0.000000   \n",
       "...         ...          ...          ...  ...          ...              ...   \n",
       "9348          2            0            8  ...     0.103601         0.000000   \n",
       "9349          1            3            1  ...     0.055612         0.000000   \n",
       "9350          7            1            0  ...     0.026490         0.000000   \n",
       "9351          0            1           80  ...     0.077989         0.000252   \n",
       "9352          1            1            0  ...     0.084000         0.000000   \n",
       "\n",
       "      char_count  word_count  avg_word_len  lexical_diversity  stopword_ratio  \\\n",
       "0           1631         242      4.805785           0.516529        0.214876   \n",
       "1            927         110      4.927273           0.745455        0.327273   \n",
       "2           1779         252      5.023810           0.595238        0.309524   \n",
       "3           1167         169      4.887574           0.644970        0.295858   \n",
       "4           1101         145      4.531034           0.703448        0.344828   \n",
       "...          ...         ...           ...                ...             ...   \n",
       "9348        2246         317      5.309148           0.321767        0.198738   \n",
       "9349        2575         394      4.928934           0.510152        0.403553   \n",
       "9350        2526         349      4.550143           0.530086        0.409742   \n",
       "9351       23803        3417      5.578578           0.282411        0.240269   \n",
       "9352        1850         265      5.584906           0.550943        0.316981   \n",
       "\n",
       "      spam_word_count        from_domain  from_tld  \n",
       "0                   0      munnari.oz.au        au  \n",
       "1                   1  cursor-system.com       com  \n",
       "2                   1           2ubh.com       com  \n",
       "3                   0         roscom.com       com  \n",
       "4                   1        ee.ed.ac.uk        uk  \n",
       "...               ...                ...       ...  \n",
       "9348                1           insiq.us        us  \n",
       "9349               11       netscape.net       net  \n",
       "9350               10           yahoo.lv        lv  \n",
       "9351               22       dialix.oz.au        au  \n",
       "9352                1      outsrc-em.com       com  \n",
       "\n",
       "[9353 rows x 32 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_processing(data_dir=\"data\", output_file=\"emails_prepared.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd0c0bf-573b-46fa-bdc8-48abad198d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46617a-a60e-45e4-be56-9b76211a4e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ecc55-1838-4640-9032-ef32d0363a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75751236-f04f-47fa-bdaf-f5c6d5b3d826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
